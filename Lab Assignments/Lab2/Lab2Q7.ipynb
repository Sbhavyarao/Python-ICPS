{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2Q7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nktLtpA8jssP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz_AYI5Vj5_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the size of our encoded representations\n",
        "encoding_dim = 24\n",
        "# 32 floats -> compression of factor 24.5, assuming the input is 784 floats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM2gFs66j6rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)\n",
        "# seperate encoder model\n",
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)\n",
        "# create a seperate decoder model\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SkG3XwTj_FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1oJfE5TkCMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "2facf0d2-83e6-4594-be37-156f6b79ed62"
      },
      "source": [
        "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "# tensorboard = TensorBoard(write_graph=True, log_dir=\"/tmp/tensor-board/auto-encoders\", histogram_freq=0)\n",
        "autoencoder.fit(x_train, x_train,epochs=20,batch_size=256,shuffle=True,verbose=1, validation_data=(x_test, x_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.3652 - val_loss: 0.2727\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2672 - val_loss: 0.2582\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2490 - val_loss: 0.2373\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2300 - val_loss: 0.2199\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2149 - val_loss: 0.2069\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.2033 - val_loss: 0.1965\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1936 - val_loss: 0.1877\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1857 - val_loss: 0.1810\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1794 - val_loss: 0.1753\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1742 - val_loss: 0.1705\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1697 - val_loss: 0.1662\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1657 - val_loss: 0.1624\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1621 - val_loss: 0.1590\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1588 - val_loss: 0.1558\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.1558 - val_loss: 0.1531\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1530 - val_loss: 0.1503\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1505 - val_loss: 0.1479\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.1481 - val_loss: 0.1455\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1459 - val_loss: 0.1434\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1438 - val_loss: 0.1413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd55e3c0cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_eFA0G7MLjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsh-_-xZk2vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "980e18f3-5d7e-4b54-ddef-3afad0be7dcb"
      },
      "source": [
        "# use Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# displaying original and reconstructed image\n",
        "n = 1  # how many images we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i+4].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i+4].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JFGMJ0dM013",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}