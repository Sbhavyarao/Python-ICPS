{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dl_Icp1.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMd10ooehnynOzaaD/Ie5Le"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"e1ToW6dYhuBR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":99},"outputId":"3ae0ba44-1271-4fe5-97f4-855dca0ba06b","executionInfo":{"status":"ok","timestamp":1584919269248,"user_tz":300,"elapsed":4737,"user":{"displayName":"bhavya Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxlGdh-uK-nRjtOHg-R_42WiUfpHnKZIbE9iFs0g=s64","userId":"02224452376464609376"}}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","# loading the dataset\n","\n","dataset = pd.read_csv(\"/content/diabetes.csv\", header=None).values\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5k19RYuri37u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"de17439d-b99d-4394-e27c-78e9067fc9a0","executionInfo":{"status":"ok","timestamp":1584919295155,"user_tz":300,"elapsed":4095,"user":{"displayName":"bhavya Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxlGdh-uK-nRjtOHg-R_42WiUfpHnKZIbE9iFs0g=s64","userId":"02224452376464609376"}}},"source":["np.random.seed(42)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(21, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","576/576 [==============================] - 1s 1ms/step - loss: 4.1986 - acc: 0.5017\n","Epoch 2/100\n","576/576 [==============================] - 0s 39us/step - loss: 3.0890 - acc: 0.5660\n","Epoch 3/100\n","576/576 [==============================] - 0s 42us/step - loss: 2.4913 - acc: 0.5868\n","Epoch 4/100\n","576/576 [==============================] - 0s 41us/step - loss: 2.2771 - acc: 0.5868\n","Epoch 5/100\n","576/576 [==============================] - 0s 38us/step - loss: 2.0363 - acc: 0.6059\n","Epoch 6/100\n","576/576 [==============================] - 0s 46us/step - loss: 1.7871 - acc: 0.6128\n","Epoch 7/100\n","576/576 [==============================] - 0s 41us/step - loss: 1.5915 - acc: 0.6233\n","Epoch 8/100\n","576/576 [==============================] - 0s 44us/step - loss: 1.4748 - acc: 0.6111\n","Epoch 9/100\n","576/576 [==============================] - 0s 39us/step - loss: 1.3483 - acc: 0.6128\n","Epoch 10/100\n","576/576 [==============================] - 0s 40us/step - loss: 1.1864 - acc: 0.6562\n","Epoch 11/100\n","576/576 [==============================] - 0s 42us/step - loss: 1.0424 - acc: 0.6667\n","Epoch 12/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.9817 - acc: 0.6441\n","Epoch 13/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.9307 - acc: 0.6580\n","Epoch 14/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.7862 - acc: 0.6632\n","Epoch 15/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.7439 - acc: 0.6562\n","Epoch 16/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.7126 - acc: 0.6753\n","Epoch 17/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.6857 - acc: 0.6788\n","Epoch 18/100\n","576/576 [==============================] - 0s 36us/step - loss: 0.7118 - acc: 0.6667\n","Epoch 19/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.7307 - acc: 0.6649\n","Epoch 20/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.7439 - acc: 0.6372\n","Epoch 21/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.7301 - acc: 0.6562\n","Epoch 22/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6529 - acc: 0.6701\n","Epoch 23/100\n","576/576 [==============================] - 0s 37us/step - loss: 0.6406 - acc: 0.6649\n","Epoch 24/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.6559 - acc: 0.6771\n","Epoch 25/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.6259 - acc: 0.6944\n","Epoch 26/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.6478 - acc: 0.6858\n","Epoch 27/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6135 - acc: 0.6667\n","Epoch 28/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6184 - acc: 0.6892\n","Epoch 29/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6091 - acc: 0.6649\n","Epoch 30/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.6028 - acc: 0.6875\n","Epoch 31/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.6031 - acc: 0.6823\n","Epoch 32/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5963 - acc: 0.6910\n","Epoch 33/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.6159 - acc: 0.6806\n","Epoch 34/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6135 - acc: 0.7014\n","Epoch 35/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.5993 - acc: 0.6840\n","Epoch 36/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.6059 - acc: 0.7066\n","Epoch 37/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.6420 - acc: 0.6615\n","Epoch 38/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5980 - acc: 0.7014\n","Epoch 39/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5940 - acc: 0.7066\n","Epoch 40/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5770 - acc: 0.6892\n","Epoch 41/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.6153 - acc: 0.6788\n","Epoch 42/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.6134 - acc: 0.7049\n","Epoch 43/100\n","576/576 [==============================] - 0s 37us/step - loss: 0.5954 - acc: 0.6910\n","Epoch 44/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5861 - acc: 0.7101\n","Epoch 45/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5813 - acc: 0.7049\n","Epoch 46/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5884 - acc: 0.7014\n","Epoch 47/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.5692 - acc: 0.6979\n","Epoch 48/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.6152 - acc: 0.6823\n","Epoch 49/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5788 - acc: 0.7049\n","Epoch 50/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5723 - acc: 0.7222\n","Epoch 51/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5942 - acc: 0.7031\n","Epoch 52/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5535 - acc: 0.7240\n","Epoch 53/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5895 - acc: 0.7031\n","Epoch 54/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.6087 - acc: 0.6858\n","Epoch 55/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5758 - acc: 0.7135\n","Epoch 56/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5731 - acc: 0.7031\n","Epoch 57/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5712 - acc: 0.7066\n","Epoch 58/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.6016 - acc: 0.7083\n","Epoch 59/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5670 - acc: 0.6979\n","Epoch 60/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5562 - acc: 0.7014\n","Epoch 61/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5885 - acc: 0.6962\n","Epoch 62/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5823 - acc: 0.7014\n","Epoch 63/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5622 - acc: 0.7257\n","Epoch 64/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5570 - acc: 0.7431\n","Epoch 65/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5632 - acc: 0.7205\n","Epoch 66/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5487 - acc: 0.7153\n","Epoch 67/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5739 - acc: 0.7014\n","Epoch 68/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5537 - acc: 0.7309\n","Epoch 69/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.5437 - acc: 0.7396\n","Epoch 70/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5597 - acc: 0.6979\n","Epoch 71/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.5505 - acc: 0.7240\n","Epoch 72/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5481 - acc: 0.7326\n","Epoch 73/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.5464 - acc: 0.7309\n","Epoch 74/100\n","576/576 [==============================] - 0s 37us/step - loss: 0.5448 - acc: 0.7361\n","Epoch 75/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.5687 - acc: 0.7188\n","Epoch 76/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5872 - acc: 0.7101\n","Epoch 77/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5377 - acc: 0.7326\n","Epoch 78/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5808 - acc: 0.7292\n","Epoch 79/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5545 - acc: 0.7344\n","Epoch 80/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5395 - acc: 0.7448\n","Epoch 81/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5631 - acc: 0.7222\n","Epoch 82/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5472 - acc: 0.7378\n","Epoch 83/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5244 - acc: 0.7448\n","Epoch 84/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5433 - acc: 0.7274\n","Epoch 85/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5772 - acc: 0.6910\n","Epoch 86/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5735 - acc: 0.7118\n","Epoch 87/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5283 - acc: 0.7431\n","Epoch 88/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.5665 - acc: 0.7188\n","Epoch 89/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5478 - acc: 0.7326\n","Epoch 90/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.5532 - acc: 0.7292\n","Epoch 91/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5720 - acc: 0.7118\n","Epoch 92/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.5246 - acc: 0.7535\n","Epoch 93/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5212 - acc: 0.7569\n","Epoch 94/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.5524 - acc: 0.7153\n","Epoch 95/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5752 - acc: 0.7066\n","Epoch 96/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5537 - acc: 0.7222\n","Epoch 97/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5631 - acc: 0.7188\n","Epoch 98/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5315 - acc: 0.7431\n","Epoch 99/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5273 - acc: 0.7431\n","Epoch 100/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5200 - acc: 0.7396\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VylpPokfjJ3G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":277},"outputId":"de4d4db2-4bef-426e-e6e9-59c1e536c2dc","executionInfo":{"status":"ok","timestamp":1584919317236,"user_tz":300,"elapsed":348,"user":{"displayName":"bhavya Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxlGdh-uK-nRjtOHg-R_42WiUfpHnKZIbE9iFs0g=s64","userId":"02224452376464609376"}}},"source":["print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 21)                189       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 22        \n","=================================================================\n","Total params: 211\n","Trainable params: 211\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","192/192 [==============================] - 0s 176us/step\n","[0.6301263272762299, 0.6822916666666666]\n"],"name":"stdout"}]}]}